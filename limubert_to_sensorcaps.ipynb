{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_subsampled_string(data, n=20):\n",
    "    if len(data)/n>10:\n",
    "        print(f\"High compression: {len(data)/n}\")\n",
    "    indices = np.round(np.linspace(0, len(data) - 1, n)).astype(int)\n",
    "    return str([data[idx] for idx in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def limubert_sample_to_sensorcaps(summary, accl_str, gyro_str):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"Please consider yourself to be an expert on gyroscope and accelerometer sensor \"\n",
    "                \"information given as a metadata of IMU datasets.\"\n",
    "                \"You are given the IMU sensor readings of a human activity. \"\n",
    "                \"The user also provides a brief summary of the event followed by 'Summary:'. \"\n",
    "                \"They also give you gyroscopic and accelerometer sensor data followed by \"\n",
    "                \"'Gyroscope:' and 'Accelerometer:' respectively. \"\n",
    "                \"They are written in a Python list of lists format and contain x, y, and z \"\n",
    "                \"axis data respectively. \"\n",
    "                \"You should provide a comprehensive details of what the characteristic IMU \"\n",
    "                \"features for that event would be within 10 words, followed by 'Features:'.\"\n",
    "                \"Then, narrate the temporal event with details that are context-aware \"\n",
    "                \"based on the sensor data, followed by 'Narration:', in a step-by-step \"\n",
    "                \"fashion, analyzing it within 150 words or less.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Summary: {summary}, \"\n",
    "                f\"Gyroscope: {gyro_str} \"\n",
    "                f\"Accelerometer: {accl_str}\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    params = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 300,\n",
    "    }\n",
    "\n",
    "    result = client.chat.completions.create(**params)\n",
    "    narration = result.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": narration})\n",
    "    sensorcaps_sample = json.dumps({\"messages\": messages})\n",
    "    return sensorcaps_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                      | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 25/25 [01:45<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 25/25 [02:17<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoaib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 25/25 [02:06<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 25/25 [02:03<00:00,  4.96s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "SAMPLES_PER_DATASET = 25\n",
    "\n",
    "root_data_dir = \"/hdd/LLM/limuBERT_data/extracted_data\"\n",
    "datasets = sorted(os.listdir(root_data_dir))\n",
    "\n",
    "data_file_name = \"data_20_120.npy\"\n",
    "label_file_name = \"label_20_120.npy\"\n",
    "\n",
    "\n",
    "with open('/hdd/LLM/limuBERT_data/dataset_activity_label.json') as json_file:\n",
    "    dataset_activity_label_dict = json.load(json_file)\n",
    "\n",
    "\n",
    "last_axis_dict = {\n",
    "    \"hhar\": 2, \"motion\":0, \"shoaib\":0, \"uci\":0\n",
    "}\n",
    "with open(\"sensorcaps_untrained.jsonl\",\"w\") as f:\n",
    "    for dataset in datasets:\n",
    "        data = np.load(os.path.join(root_data_dir, dataset, data_file_name))\n",
    "        label = np.load(os.path.join(root_data_dir, dataset, label_file_name))\n",
    "        label_dict = dataset_activity_label_dict[dataset]\n",
    "        last_axis = last_axis_dict[dataset]\n",
    "        print(dataset)\n",
    "        \n",
    "        indices = random.sample(range(1, data.shape[0]), SAMPLES_PER_DATASET)\n",
    "        for sample_index in tqdm(indices):\n",
    "            sample_data = data[sample_index]\n",
    "            key = str(int(label[sample_index, 0, last_axis]))\n",
    "            sample_label = label_dict[str(int(label[sample_index, 0, last_axis]))]\n",
    "            accl, gyro = data[0][:, 0:3], data[0][:, 3:6]\n",
    "            accl, gyro = accl.tolist(), gyro.tolist()\n",
    "            accl_str = str(accl)\n",
    "            gyro_str = str(gyro)\n",
    "            sensorcaps_sample = limubert_sample_to_sensorcaps(\n",
    "                summary=sample_label,\n",
    "                accl_str=accl_str,\n",
    "                gyro_str=gyro_str\n",
    "            )\n",
    "            f.write(sensorcaps_sample+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
